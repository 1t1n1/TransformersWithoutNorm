{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import pathlib\n",
    "\n",
    "epoch_pattern = re.compile(r\"^starting epoch:\\s*(\\d+)\")\n",
    "starting_pattern = re.compile(r\"^Starting training.*\")\n",
    "train_metrics_pattern = re.compile(r\"Train -\\s+loss:\\s*([\\d.]+)\\s+top-1:\\s*([\\d.]+)\\s+top-5:\\s*([\\d.]+)\\s+top-10:\\s*([\\d.]+)\")\n",
    "eval_metrics_pattern = re.compile(r\"Eval -\\s+loss:\\s*([\\d.]+)\\s+top-1:\\s*([\\d.]+)\\s+top-5:\\s*([\\d.]+)\\s+top-10:\\s*([\\d.]+)\")\n",
    "\n",
    "name_var_pattern = re.compile(r\"-?((?P<varname>[a-zA-Z\\-_]+)=(?P<value>\\-?\\d+\\.?\\d*(e\\-?\\d+)?))\")\n",
    "name_pattern = re.compile(r\"^(?P<exp_group>[\\d]+)?\\-?(?P<Layer>.+)(?P<Position>Pre|Post|Both)(?P<DyTfn>.*tanh)?(?P<Vars>(([a-zA-Z\\-_]+)=([\\d\\.e\\-]+))*)$\")\n",
    "\n",
    "\n",
    "def parse_name(name):\n",
    "    out = {\"exp_group\":1, 'lr':1e-4, 'dim_hidden':256}\n",
    "    search = name_pattern.search(name)\n",
    "    if search is None:\n",
    "        out[\"Layer\"] = \"Identity\"\n",
    "        out[\"Position\"] = \"Both\"\n",
    "        return out\n",
    "    out[\"Layer\"] = search.group(\"Layer\")\n",
    "    if out[\"Layer\"]==\"DyT\":\n",
    "        out[\"Alpha\"] = 0.5\n",
    "        out[\"DyTfn\"] = \"Tanh\"\n",
    "    out[\"Position\"] = search.group(\"Position\")\n",
    "    if search.group(\"DyTfn\") is not None:\n",
    "        out[\"DyTfn\"] = search.group(\"DyTfn\")\n",
    "    if search.group(\"exp_group\") is not None:\n",
    "        out[\"exp_group\"] = int(search.group(\"exp_group\"))\n",
    "    out.update({e[1]:float(e[2]) for e in name_var_pattern.findall(search.group(\"Vars\"))})\n",
    "    return out\n",
    "\n",
    "def read_log(folder):\n",
    "    data_rows = []\n",
    "    current_epoch = None\n",
    "    train_metrics = {}\n",
    "    eval_metrics = {}\n",
    "    english = None\n",
    "    french = None\n",
    "    current_model = folder.name\n",
    "    smallest_epoch = None\n",
    "    \n",
    "    with open(folder/\"training_logs.log\", \"r\", encoding=\"utf-8\") as f:\n",
    "        current_model_data = []\n",
    "        for line in f.readlines():\n",
    "            line = line.strip()\n",
    "            \n",
    "            if match := starting_pattern.match(line):\n",
    "                continue\n",
    "\n",
    "            if match := epoch_pattern.match(line):\n",
    "                if smallest_epoch is None:\n",
    "                    smallest_epoch = int(match.group(1))\n",
    "                current_epoch = int(match.group(1))-smallest_epoch\n",
    "                continue\n",
    "\n",
    "            if match := train_metrics_pattern.match(line):\n",
    "                train_metrics = {\n",
    "                    \"Train Loss\": float(match.group(1)),\n",
    "                    \"Train Top-1\": float(match.group(2)),\n",
    "                    \"Train Top-5\": float(match.group(3)),\n",
    "                    \"Train Top-10\": float(match.group(4)),\n",
    "                }\n",
    "                continue\n",
    "\n",
    "            if match := eval_metrics_pattern.match(line):\n",
    "                eval_metrics = {\n",
    "                    \"Eval Loss\": float(match.group(1)),\n",
    "                    \"Eval Top-1\": float(match.group(2)),\n",
    "                    \"Eval Top-5\": float(match.group(3)),\n",
    "                    \"Eval Top-10\": float(match.group(4)),\n",
    "                }\n",
    "                continue\n",
    "\n",
    "            if english is None:\n",
    "                english = line\n",
    "                continue\n",
    "            elif french is None:\n",
    "                french = line\n",
    "                row = {\n",
    "                    **parse_name(current_model),\n",
    "                    \"Exp_full_name\": current_model,\n",
    "                    \"Epoch\": current_epoch,\n",
    "                    \"Ground Truth\": english,\n",
    "                    \"Prediction\": french,\n",
    "                    **train_metrics,\n",
    "                    **eval_metrics,\n",
    "                }\n",
    "                current_model_data.append(row)\n",
    "                english = None\n",
    "                french = None\n",
    "                continue\n",
    "\n",
    "    data_rows.extend(current_model_data)\n",
    "    current_model_data = []\n",
    "    return data_rows\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = [e for e in pathlib.Path(\"logs\").glob(\"*\") if e.is_dir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = []\n",
    "for e in runs: \n",
    "    logs += read_log(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {k:[] for e in logs for k in e.keys()}\n",
    "\n",
    "for e in logs:\n",
    "    for k in data.keys():\n",
    "        data[k].append(e.get(k))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"Layer\",\"Position\",\"Epoch\",\"Train Loss\",\"Eval Loss\",\"Alpha\",\"DyTfn\",\"exp_group\",\"lr\",\"dim_hidden\",\"Exp_full_name\",\"Ground Truth\",\"Prediction\",\"Train Top-1\",\"Train Top-5\",\"Train Top-10\",\"Eval Top-1\",\"Eval Top-5\",\"Eval Top-10\"]\n",
    "\n",
    "df = pd.DataFrame(data, columns=cols)\n",
    "df.to_csv(\"out.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Eval Loss</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>exp_group</th>\n",
       "      <th>lr</th>\n",
       "      <th>dim_hidden</th>\n",
       "      <th>Train Top-1</th>\n",
       "      <th>Train Top-5</th>\n",
       "      <th>Train Top-10</th>\n",
       "      <th>Eval Top-1</th>\n",
       "      <th>Eval Top-5</th>\n",
       "      <th>Eval Top-10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>280.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>280.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.165000</td>\n",
       "      <td>3.449250</td>\n",
       "      <td>0.472368</td>\n",
       "      <td>1.732143</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>269.714286</td>\n",
       "      <td>0.459036</td>\n",
       "      <td>0.645607</td>\n",
       "      <td>0.701429</td>\n",
       "      <td>0.451393</td>\n",
       "      <td>0.625536</td>\n",
       "      <td>0.678250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.416746</td>\n",
       "      <td>1.416747</td>\n",
       "      <td>2.252221</td>\n",
       "      <td>0.295177</td>\n",
       "      <td>0.835826</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>57.746732</td>\n",
       "      <td>0.190482</td>\n",
       "      <td>0.192012</td>\n",
       "      <td>0.177365</td>\n",
       "      <td>0.206866</td>\n",
       "      <td>0.226862</td>\n",
       "      <td>0.217559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.160000</td>\n",
       "      <td>1.290000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.090000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.007500</td>\n",
       "      <td>1.930000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.317500</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.545000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.780000</td>\n",
       "      <td>2.680000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>0.515000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.132500</td>\n",
       "      <td>4.452500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.890000</td>\n",
       "      <td>14.880000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>512.000000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.920000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Epoch  Train Loss   Eval Loss       Alpha   exp_group          lr  \\\n",
       "count  280.000000  280.000000  280.000000  190.000000  280.000000  280.000000   \n",
       "mean     2.000000    3.165000    3.449250    0.472368    1.732143    0.000120   \n",
       "std      1.416746    1.416747    2.252221    0.295177    0.835826    0.000086   \n",
       "min      0.000000    1.160000    1.290000    0.050000    1.000000    0.000025   \n",
       "25%      1.000000    2.007500    1.930000    0.500000    1.000000    0.000100   \n",
       "50%      2.000000    2.780000    2.680000    0.500000    1.000000    0.000100   \n",
       "75%      3.000000    4.132500    4.452500    0.500000    2.250000    0.000100   \n",
       "max      4.000000    5.890000   14.880000    1.000000    3.000000    0.000400   \n",
       "\n",
       "       dim_hidden  Train Top-1  Train Top-5  Train Top-10  Eval Top-1  \\\n",
       "count  280.000000   280.000000   280.000000    280.000000  280.000000   \n",
       "mean   269.714286     0.459036     0.645607      0.701429    0.451393   \n",
       "std     57.746732     0.190482     0.192012      0.177365    0.206866   \n",
       "min    256.000000     0.090000     0.260000      0.330000    0.030000   \n",
       "25%    256.000000     0.340000     0.520000      0.590000    0.317500   \n",
       "50%    256.000000     0.515000     0.700000      0.750000    0.520000   \n",
       "75%    256.000000     0.610000     0.800000      0.850000    0.620000   \n",
       "max    512.000000     0.730000     0.910000      0.940000    0.710000   \n",
       "\n",
       "       Eval Top-5  Eval Top-10  \n",
       "count  280.000000   280.000000  \n",
       "mean     0.625536     0.678250  \n",
       "std      0.226862     0.217559  \n",
       "min      0.070000     0.090000  \n",
       "25%      0.475000     0.545000  \n",
       "50%      0.710000     0.760000  \n",
       "75%      0.810000     0.850000  \n",
       "max      0.890000     0.920000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.query(\"Epoch==4 & exp_group==3 & Layer=='DyT' & Position=='Pre'\").groupby([\"DyTfn\"])['Eval Loss'].idxmin()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer</th>\n",
       "      <th>Position</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Eval Loss</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>DyTfn</th>\n",
       "      <th>exp_group</th>\n",
       "      <th>lr</th>\n",
       "      <th>dim_hidden</th>\n",
       "      <th>Exp_full_name</th>\n",
       "      <th>Ground Truth</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Train Top-1</th>\n",
       "      <th>Train Top-5</th>\n",
       "      <th>Train Top-10</th>\n",
       "      <th>Eval Top-1</th>\n",
       "      <th>Eval Top-5</th>\n",
       "      <th>Eval Top-10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>DyT</td>\n",
       "      <td>Pre</td>\n",
       "      <td>4</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Hardtanh</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>256.0</td>\n",
       "      <td>3-DyTPreHardtanhAlpha-dim_hidden=512</td>\n",
       "      <td>It's more trouble than it's worth.</td>\n",
       "      <td>C'est plus grand que ça en vaut la peine.</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>DyT</td>\n",
       "      <td>Pre</td>\n",
       "      <td>4</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0.5</td>\n",
       "      <td>LeakyHardtanh</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>256.0</td>\n",
       "      <td>3-DyTPreLeakyHardtanhAlpha-dim_hidden=512</td>\n",
       "      <td>It's more trouble than it's worth.</td>\n",
       "      <td>C'est plus grand que ça en vaut la peine.</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>DyT</td>\n",
       "      <td>Pre</td>\n",
       "      <td>4</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Tanh</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>256.0</td>\n",
       "      <td>3-DyTPre-lr=0.0004</td>\n",
       "      <td>We're not really sure.</td>\n",
       "      <td>Nous ne sommes pas vraiment sûr.</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Layer Position  Epoch  Train Loss  Eval Loss  Alpha          DyTfn  \\\n",
       "254   DyT      Pre      4        1.19       1.34    0.5       Hardtanh   \n",
       "259   DyT      Pre      4        1.19       1.34    0.5  LeakyHardtanh   \n",
       "234   DyT      Pre      4        1.18       1.31    0.5           Tanh   \n",
       "\n",
       "     exp_group      lr  dim_hidden                              Exp_full_name  \\\n",
       "254          3  0.0001       256.0       3-DyTPreHardtanhAlpha-dim_hidden=512   \n",
       "259          3  0.0001       256.0  3-DyTPreLeakyHardtanhAlpha-dim_hidden=512   \n",
       "234          3  0.0004       256.0                         3-DyTPre-lr=0.0004   \n",
       "\n",
       "                           Ground Truth  \\\n",
       "254  It's more trouble than it's worth.   \n",
       "259  It's more trouble than it's worth.   \n",
       "234              We're not really sure.   \n",
       "\n",
       "                                    Prediction  Train Top-1  Train Top-5  \\\n",
       "254  C'est plus grand que ça en vaut la peine.         0.73          0.9   \n",
       "259  C'est plus grand que ça en vaut la peine.         0.73          0.9   \n",
       "234           Nous ne sommes pas vraiment sûr.         0.72          0.9   \n",
       "\n",
       "     Train Top-10  Eval Top-1  Eval Top-5  Eval Top-10  \n",
       "254          0.93         0.7        0.88         0.91  \n",
       "259          0.93         0.7        0.88         0.91  \n",
       "234          0.93         0.7        0.89         0.92  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.query(\"Epoch==4 & exp_group==2 & Layer=='DyT'\").groupby([\"DyTfn\"])['Eval Loss'].idxmin()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8839/3667664872.py:1: FutureWarning: The provided callable <function min at 0x75caac12d3a0> is currently using SeriesGroupBy.min. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"min\" instead.\n",
      "  a = list(df.query(\"Epoch==4\").groupby([\"Layer\"]).agg({\"Eval Loss\": np.min}).values.flatten())\n"
     ]
    }
   ],
   "source": [
    "a = list(df.query(\"Epoch==4\").groupby([\"Layer\"]).agg({\"Eval Loss\": np.min}).values.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer</th>\n",
       "      <th>Position</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Eval Loss</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>DyTfn</th>\n",
       "      <th>exp_group</th>\n",
       "      <th>lr</th>\n",
       "      <th>dim_hidden</th>\n",
       "      <th>Exp_full_name</th>\n",
       "      <th>Ground Truth</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Train Top-1</th>\n",
       "      <th>Train Top-5</th>\n",
       "      <th>Train Top-10</th>\n",
       "      <th>Eval Top-1</th>\n",
       "      <th>Eval Top-5</th>\n",
       "      <th>Eval Top-10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BatchNorm</td>\n",
       "      <td>Pre</td>\n",
       "      <td>4</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>256.0</td>\n",
       "      <td>BatchNormPre</td>\n",
       "      <td>We're not really sure.</td>\n",
       "      <td>Nous ne sommes pas vraiment sûre.</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Identity</td>\n",
       "      <td>Both</td>\n",
       "      <td>4</td>\n",
       "      <td>1.74</td>\n",
       "      <td>1.71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>256.0</td>\n",
       "      <td>Identity</td>\n",
       "      <td>We're not really sure.</td>\n",
       "      <td>Nous ne sommes pas vraiment sûre.</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Layernorm</td>\n",
       "      <td>Pre</td>\n",
       "      <td>4</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>256.0</td>\n",
       "      <td>LayernormPre</td>\n",
       "      <td>We're not really sure.</td>\n",
       "      <td>Nous ne sommes pas vraiment sûres.</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>RMSNorm</td>\n",
       "      <td>Pre</td>\n",
       "      <td>4</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>256.0</td>\n",
       "      <td>RMSNormPre</td>\n",
       "      <td>We're not really sure.</td>\n",
       "      <td>Nous ne sommes pas vraiment sûres.</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>Layernorm</td>\n",
       "      <td>Post</td>\n",
       "      <td>2</td>\n",
       "      <td>1.77</td>\n",
       "      <td>1.71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>256.0</td>\n",
       "      <td>2-LayernormPost-lr=0.0002</td>\n",
       "      <td>I think this isn't correct.</td>\n",
       "      <td>Je ne pense pas que ce soit correct.</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>DyT</td>\n",
       "      <td>Pre</td>\n",
       "      <td>2</td>\n",
       "      <td>1.74</td>\n",
       "      <td>1.71</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Tanh</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>256.0</td>\n",
       "      <td>3-DyTPre-lr=0.0002</td>\n",
       "      <td>I think this isn't correct.</td>\n",
       "      <td>Je ne pense pas que ce soit correct.</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>DyT</td>\n",
       "      <td>Pre</td>\n",
       "      <td>4</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Tanh</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>256.0</td>\n",
       "      <td>3-DyTPre-lr=0.0004</td>\n",
       "      <td>We're not really sure.</td>\n",
       "      <td>Nous ne sommes pas vraiment sûr.</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>Layernorm</td>\n",
       "      <td>Pre</td>\n",
       "      <td>4</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>256.0</td>\n",
       "      <td>3-LayernormPre-lr=0.0004</td>\n",
       "      <td>We're not really sure.</td>\n",
       "      <td>Nous ne sommes pas vraiment sûrs.</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Layer Position  Epoch  Train Loss  Eval Loss  Alpha DyTfn  exp_group  \\\n",
       "14   BatchNorm      Pre      4        1.70       1.69    NaN  None          1   \n",
       "109   Identity     Both      4        1.74       1.71    NaN  None          1   \n",
       "124  Layernorm      Pre      4        1.71       1.70    NaN  None          1   \n",
       "139    RMSNorm      Pre      4        1.71       1.70    NaN  None          1   \n",
       "162  Layernorm     Post      2        1.77       1.71    NaN  None          2   \n",
       "227        DyT      Pre      2        1.74       1.71    0.5  Tanh          3   \n",
       "234        DyT      Pre      4        1.18       1.31    0.5  Tanh          3   \n",
       "269  Layernorm      Pre      4        1.16       1.29    NaN  None          3   \n",
       "\n",
       "         lr  dim_hidden              Exp_full_name  \\\n",
       "14   0.0001       256.0               BatchNormPre   \n",
       "109  0.0001       256.0                   Identity   \n",
       "124  0.0001       256.0               LayernormPre   \n",
       "139  0.0001       256.0                 RMSNormPre   \n",
       "162  0.0002       256.0  2-LayernormPost-lr=0.0002   \n",
       "227  0.0002       256.0         3-DyTPre-lr=0.0002   \n",
       "234  0.0004       256.0         3-DyTPre-lr=0.0004   \n",
       "269  0.0004       256.0   3-LayernormPre-lr=0.0004   \n",
       "\n",
       "                    Ground Truth                            Prediction  \\\n",
       "14        We're not really sure.     Nous ne sommes pas vraiment sûre.   \n",
       "109       We're not really sure.     Nous ne sommes pas vraiment sûre.   \n",
       "124       We're not really sure.    Nous ne sommes pas vraiment sûres.   \n",
       "139       We're not really sure.    Nous ne sommes pas vraiment sûres.   \n",
       "162  I think this isn't correct.  Je ne pense pas que ce soit correct.   \n",
       "227  I think this isn't correct.  Je ne pense pas que ce soit correct.   \n",
       "234       We're not really sure.      Nous ne sommes pas vraiment sûr.   \n",
       "269       We're not really sure.     Nous ne sommes pas vraiment sûrs.   \n",
       "\n",
       "     Train Top-1  Train Top-5  Train Top-10  Eval Top-1  Eval Top-5  \\\n",
       "14          0.65         0.84          0.88        0.65        0.84   \n",
       "109         0.64         0.83          0.87        0.65        0.84   \n",
       "124         0.65         0.84          0.88        0.65        0.84   \n",
       "139         0.65         0.84          0.88        0.65        0.84   \n",
       "162         0.64         0.83          0.87        0.65        0.84   \n",
       "227         0.64         0.83          0.87        0.64        0.84   \n",
       "234         0.72         0.90          0.93        0.70        0.89   \n",
       "269         0.73         0.91          0.94        0.71        0.89   \n",
       "\n",
       "     Eval Top-10  \n",
       "14          0.88  \n",
       "109         0.87  \n",
       "124         0.88  \n",
       "139         0.88  \n",
       "162         0.87  \n",
       "227         0.88  \n",
       "234         0.92  \n",
       "269         0.92  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"Eval Loss\"].apply(lambda x : x in a)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8839/2145597980.py:1: FutureWarning: The provided callable <function min at 0x75caac12d3a0> is currently using SeriesGroupBy.min. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"min\" instead.\n",
      "  df.query(\"Epoch==4 & exp_group==1\").groupby([\"Layer\", \"Position\"]).agg({\"Eval Loss\": np.min})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Eval Loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer</th>\n",
       "      <th>Position</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">BatchNorm</th>\n",
       "      <th>Both</th>\n",
       "      <td>1.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Post</th>\n",
       "      <td>1.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pre</th>\n",
       "      <td>1.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DyT</th>\n",
       "      <th>Both</th>\n",
       "      <td>3.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Post</th>\n",
       "      <td>3.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pre</th>\n",
       "      <td>1.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Identity</th>\n",
       "      <th>Both</th>\n",
       "      <td>1.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Layernorm</th>\n",
       "      <th>Both</th>\n",
       "      <td>1.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Post</th>\n",
       "      <td>1.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pre</th>\n",
       "      <td>1.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">RMSNorm</th>\n",
       "      <th>Both</th>\n",
       "      <td>1.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Post</th>\n",
       "      <td>1.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pre</th>\n",
       "      <td>1.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Eval Loss\n",
       "Layer     Position           \n",
       "BatchNorm Both           1.73\n",
       "          Post           1.74\n",
       "          Pre            1.69\n",
       "DyT       Both           3.23\n",
       "          Post           3.12\n",
       "          Pre            1.78\n",
       "Identity  Both           1.71\n",
       "Layernorm Both           1.77\n",
       "          Post           1.77\n",
       "          Pre            1.70\n",
       "RMSNorm   Both           1.77\n",
       "          Post           1.78\n",
       "          Pre            1.70"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query(\"Epoch==4 & exp_group==1\").groupby([\"Layer\", \"Position\"]).agg({\"Eval Loss\": np.min})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
